{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from pymongo import MongoClient\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from utils import *\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import jieba\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://127.0.0.1:27017', username='', password=\"\")\n",
    "dataset = client.Assess\n",
    "\n",
    "movie_info = dataset.movie_info\n",
    "user_phase1_results = dataset.user_phase1_results\n",
    "user_phase2_results = dataset.user_phase2_results\n",
    "peer_results = dataset.peer_phase1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refering Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ExpPlatform_User_P2/models.py\n",
    "def get_item_info(item_id):\n",
    "    tinfo = movie_info.find_one({'movieId': item_id})\n",
    "    if tinfo:\n",
    "        return {\"title\": tinfo['show_title'], \n",
    "                \"movieId\": tinfo['movieId'],\n",
    "                \"itemID\": tinfo['show_itemID'],\n",
    "                \"itemUrl\": \"https://movie.douban.com/subject/{}/\".format(tinfo['show_itemID']), \n",
    "                \"imgUrl\": \"/ex2\" + tinfo['show_imgUrl'],\n",
    "                \"information\": tinfo['show_information'],\n",
    "                \"summary\": tinfo['show_summary'],\n",
    "                \"directors\": tinfo[\"show_directors\"],\n",
    "                \"writers\": tinfo[\"show_writers\"],\n",
    "                \"casts\": tinfo[\"show_casts\"],\n",
    "                \"genres\": tinfo[\"show_genres\"],\n",
    "                \"countries\": tinfo[\"show_countries\"],\n",
    "                \"languages\": tinfo[\"show_languages\"],\n",
    "                \"date\": tinfo[\"show_date\"],\n",
    "                \"duration\": tinfo[\"show_duration\"],\n",
    "                \"rating_count\": int(tinfo['db_ratings_count']),\n",
    "                \"db_directors\": [(t['name'], \"/ex2/static/figures/attribute/c_{}.jpg\".format(t['id'])) for t in tinfo['db_directors']],\n",
    "                \"db_writers\": [(t['name'], \"/ex2/static/figures/attribute/c_{}.jpg\".format(t['id'])) for t in tinfo['db_writers']],\n",
    "                \"db_casts\": [(t['name'], \"/ex2/static/figures/attribute/c_{}.jpg\".format(t['id'])) for t in tinfo['db_casts']],\n",
    "                \"aka\": tinfo['show_aka']}\n",
    "    return False\n",
    "    \n",
    "def get_movie_attributes(item_id, ispeer=False):\n",
    "    movie_info = get_item_info(item_id)\n",
    "    ans_attr = []\n",
    "    namedic = {\"db_directors\": \"导演\", \"db_writers\": \"编剧\", \"db_casts\": \"主演\", \"genres\": \"类型\", \"countries\": \"制片国家/地区\"}\n",
    "    for tk in ['db_directors', 'db_writers', 'db_casts']:\n",
    "        tvs = movie_info[tk]\n",
    "        for ti, (tv, tv_url) in enumerate(tvs):\n",
    "            tans = {\n",
    "                    \"key\": namedic[tk], \n",
    "                    \"value\": tv,\n",
    "                    \"text\": \"\"\"<b>{}:</b><span style=\"text-decoration:underline\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\" title='<img src=\"{}\" style=\"height:200px\"/>'>{} </span>\"\"\".format(namedic[tk], tv_url, tv),\n",
    "                    \"key_last\": False\n",
    "                    }\n",
    "            if ti == len(tvs) - 1:\n",
    "                tans['key_last'] = True\n",
    "            ans_attr.append(tans)\n",
    "\n",
    "    for tk in ['genres', 'countries']:\n",
    "        tvs = movie_info[tk].split(\" / \")\n",
    "        for ti, tv in enumerate(tvs):\n",
    "            tans = {\n",
    "                    \"key\": namedic[tk], \n",
    "                    \"value\": tv,\n",
    "                    \"text\": \"<b>{}:</b>{} \".format(namedic[tk], tv),\n",
    "                    \"key_last\": False,\n",
    "                    \"replay\": \"no\"\n",
    "                    }\n",
    "            if ti == len(tvs) - 1:\n",
    "                tans['key_last'] = True\n",
    "            ans_attr.append(tans)\n",
    "    \n",
    "    if ispeer == False:\n",
    "        ans_attr.append({\"key\": \"热度（评分数量）\", \"value\": \"1\", \"text\": \"<b>热度（评分数量）</b>\", \"key_last\": False, \"replay\": \"no\"})\n",
    "        ans_attr.append({\"key\": \"和某部看过的电影相似\", \"value\": \"1\", \"text\": \"<b>和某部看过的电影相似</b>\", \"key_last\": False, \"replay\": \"no\"})\n",
    "        ans_attr.append({\"key\": \"我的朋友也喜欢\", \"value\": \"1\", \"text\": \"<b>我的朋友也喜欢</b>\", \"key_last\": False, \"replay\": \"no\"})\n",
    "    else:\n",
    "        ans_attr.append({\"key\": \"热度（评分数量）\", \"value\": \"1\", \"text\": \"<b>热度（评分数量）</b>\", \"key_last\": False})\n",
    "        ans_attr.append({\"key\": \"和Ta某部看过的电影相似\", \"value\": \"1\", \"text\": \"\"\"<span style=\"text-decoration:underline\" data-toggle=\"tooltip\" data-placement=\"right\" data-html=\"true\" title=\"<div style='width:200px'>例如：\b你发现这电影和Ta看过的电影A很像，但Ta不喜欢A，那可能就是负向的，反之是无影响或正向\"> <b>和某部看过的电影相似</b> </span>\"\"\", \"key_last\": True})\n",
    "    return ans_attr\n",
    "\n",
    "\"\"\" New \"\"\"\n",
    "def get_shown_attributes(item_id, ispeer=False):\n",
    "    item_attrs = get_movie_attributes(item_id, ispeer=ispeer)\n",
    "    ans = []\n",
    "    for ta in item_attrs:\n",
    "        ans.append(\"{}={}\".format(ta['key'], ta['value']))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <User, Item> Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_15123372089\n",
      "u_18801378212\n",
      "u_15810795617\n",
      "u_18811195178\n",
      "u_15900292575\n",
      "u_15071347094\n",
      "u_18222716322\n",
      "u_18811400801\n",
      "u_13701195791\n",
      "u_19801210262\n",
      "u_18712328742\n",
      "u_18993873008\n",
      "u_15313346392\n",
      "u_17801182378\n",
      "u_18800182977\n",
      "u_18221771895\n",
      "u_19920091165\n"
     ]
    }
   ],
   "source": [
    "user_ids = set([t['user_id'] for t in user_phase2_results.find() if t['user_id'] != \"u_2019310837\"])\n",
    "\n",
    "ds_user = PDtable()\n",
    "for user_id in user_ids:\n",
    "    \n",
    "    \"\"\" Drop Duplicated \"\"\"\n",
    "    print (user_id)\n",
    "    user_res = [t for t in user_phase2_results.find({\"user_id\": user_id})]\n",
    "    if len(user_res) > 1:\n",
    "        print (\"Duplicated\", user_id)\n",
    "        continue\n",
    "    user_res = user_res[0]\n",
    "    \n",
    "    \"\"\" For each item \"\"\"\n",
    "    for i, (tinfo, tlabel) in enumerate(zip(user_res['rec_item_list'], user_res['label_item_results'])):\n",
    "        \n",
    "        ans_label = [t for t in tlabel if t['page'] == \"3_detail\"][0]\n",
    "        \n",
    "        \"\"\" For attributes \"\"\"\n",
    "        keydic = {u\"热度（评分数量）=1\": u\"pop\", u\"我的朋友也喜欢=1\": u\"user\", u\"和某部看过的电影相似=1\": u\"item\"}\n",
    "        shown_attrs = get_shown_attributes(tinfo['item'], ispeer=False)\n",
    "        attr_label = {}\n",
    "        for ta in shown_attrs:\n",
    "            if ta in keydic:\n",
    "                attr_label[keydic[ta]] = \"normal\"\n",
    "            else:\n",
    "                attr_label[ta] = \"normal\"\n",
    "        \n",
    "        err = False\n",
    "        for _t in ans_label.values():\n",
    "            if type(_t) == str and _t.split(\"=\")[-1] in ['pos', 'neg', 'normal']:\n",
    "                _k, _v, _l = _t.split(\"=\")\n",
    "\n",
    "                key = \"{}={}\".format(_k, _v)\n",
    "                if key in keydic:\n",
    "                    key = keydic[key]\n",
    "                if key not in attr_label: # \n",
    "                    print (\"Error\", user_id, i, key)\n",
    "                    err = True\n",
    "                attr_label[key] = _l\n",
    "\n",
    "        self_attributes = [\"{}={}\".format(k, v) for k, v in attr_label.items()] # all attribute labels\n",
    "        pos_attrs = [k for k, v in attr_label.items() if v == \"pos\"] # positive attributes\n",
    "        normal_attrs = [k for k, v in attr_label.items() if v == \"normal\"] \n",
    "        neg_attrs = [k for k, v in attr_label.items() if v == \"neg\"]\n",
    "        assert len(pos_attrs) + len(neg_attrs) + len(normal_attrs) == len(attr_label)\n",
    "        \n",
    "        if err:\n",
    "            continue\n",
    "        \n",
    "        \"\"\" Build \"\"\"\n",
    "        ds_user.add(user_id, \"user_id\")\n",
    "        ds_user.add(tinfo['item'], \"movie_id\") #  # item = movielens ID\n",
    "        \n",
    "        ds_user.add(ans_label['watch_intent'], \"post_watch_intent\")\n",
    "        ds_user.add(ans_label['expected_preference'], \"post_expected_preference\")\n",
    "        ds_user.add(ans_label['self_explanation'], \"self_explanation\")\n",
    "        ds_user.add(self_attributes, \"self_attributes\")\n",
    "        ds_user.add(pos_attrs, \"self_pos\")\n",
    "        ds_user.add(normal_attrs, \"self_normal\")\n",
    "        ds_user.add(neg_attrs, \"self_neg\")\n",
    "        ds_user.add(ans_label['ifwatched'], \"ifwatched\")\n",
    "        \n",
    "        ds_user.add(user_res['user_summary_ans'], \"self_summary\")\n",
    "        ds_user.add(user_res['user_rank_ans']['rank-output'], \"rank_ans\")\n",
    "            \n",
    "df_user = ds_user.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Peer, User, Item> Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_peer_ans(expl_ans):\n",
    "    temp = {}\n",
    "    for tk in expl_ans:\n",
    "        task_id, task_key = tk.split(\"-\")\n",
    "        task_id = int(task_id)\n",
    "\n",
    "        temp.setdefault(task_id, {})\n",
    "        if task_key in ['itemId', 'peer_explanation_long']:\n",
    "            temp[task_id][task_key] = expl_ans[tk]\n",
    "        elif task_key in ['peer_watch_intent', 'peer_preference', \n",
    "                          'peer_ifwatched', 'peer_own_preference']:\n",
    "            temp[task_id][task_key] = int(expl_ans[tk])\n",
    "        else:\n",
    "            temp[task_id].setdefault(\"attr_factors\", [])\n",
    "            temp[task_id]['attr_factors'].append(expl_ans[tk])\n",
    "\n",
    "    ans = [temp[i] for i in range(1, len(temp) + 1)]\n",
    "    return ans\n",
    "\n",
    "def parse_time_list(tinfo):\n",
    "    summary_time_list = []\n",
    "    estimate_time_list = []\n",
    "    summary_flag, estimate_flag = False, False\n",
    "    for tname, ttime in tinfo['time_list']:\n",
    "        if tname == \"task_begin-out\":\n",
    "            summary_flag, estimate_flag = True, True\n",
    "        elif summary_flag and tname == \"user_summary-in\":\n",
    "            summary_time_list.append([pd.to_datetime(ttime, unit=\"s\"),])\n",
    "        elif summary_flag and tname == \"user_summary-out\":\n",
    "            summary_time_list[-1] = (pd.to_datetime(ttime, unit=\"s\") - summary_time_list[-1][0]).total_seconds()\n",
    "            summary_flag = False\n",
    "        elif estimate_flag and tname == \"peer_explanation-in\":\n",
    "            estimate_time_list.append([pd.to_datetime(ttime, unit=\"s\"),])\n",
    "        elif estimate_flag and tname == \"peer_explanation-out\":\n",
    "            estimate_time_list[-1] = (pd.to_datetime(ttime, unit=\"s\") - estimate_time_list[-1][0]).total_seconds()\n",
    "            estimate_flag = False\n",
    "            \n",
    "    return summary_time_list, estimate_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_15033065144 4\n",
      "-- u_18221771895\n",
      "-- u_18397123106\n",
      "-- u_18811400801\n",
      "e_18811378926 4\n",
      "-- u_17801182378\n",
      "-- u_13572956735\n",
      "-- u_18993873008\n",
      "e_15313387657 4\n",
      "-- u_17801182378\n",
      "-- u_13572956735\n",
      "-- u_18993873008\n",
      "e_13015242799 4\n",
      "-- u_19920091165\n",
      "-- u_15313346392\n",
      "-- u_13701195791\n",
      "e_13552099266 4\n",
      "-- u_19920091165\n",
      "-- u_15810795617\n",
      "-- u_18811195178\n",
      "e_18811307291 4\n",
      "-- u_18221771895\n",
      "-- u_18397123106\n",
      "-- u_18811400801\n",
      "e_13522737135 4\n",
      "-- u_18712328742\n",
      "-- u_19801210262\n",
      "-- u_15313346392\n",
      "e_18701593682 4\n",
      "-- u_15810795617\n",
      "-- u_15900292575\n",
      "-- u_18222716322\n",
      "e_18810755387 4\n",
      "-- u_15900292575\n",
      "-- u_17801182378\n",
      "-- u_18811400801\n",
      "e_18211082695 4\n",
      "-- u_15313346392\n",
      "-- u_15071347094\n",
      "-- u_18712328742\n",
      "e_13001261200 4\n",
      "-- u_18993873008\n",
      "-- u_15810795617\n",
      "-- u_15071347094\n",
      "e_18813035877 4\n",
      "-- u_15232417786\n",
      "-- u_18222716322\n",
      "-- u_18811195178\n",
      "e_13029231055 4\n",
      "-- u_18221771895\n",
      "-- u_15071347094\n",
      "-- u_18800182977\n",
      "e_18801357182 4\n",
      "-- u_18800182977\n",
      "-- u_15900292575\n",
      "-- u_19801210262\n",
      "e_13120301998 4\n",
      "-- u_15232417786\n",
      "-- u_18222716322\n",
      "-- u_18811195178\n",
      "e_15201521732 4\n",
      "-- u_18801378212\n",
      "-- u_18800182977\n",
      "-- u_15900292575\n",
      "e_19825618235 4\n",
      "-- u_18811307175\n",
      "-- u_18801378212\n",
      "-- u_19920091165\n",
      "e_15810378606 4\n",
      "-- u_13701195791\n",
      "-- u_18801378212\n",
      "-- u_18712328742\n",
      "e_18746767666 3\n",
      "-- u_13701195791\n",
      "-- u_19801210262\n"
     ]
    }
   ],
   "source": [
    "exp_ids = [t['user_id'] for t in peer_results.find() if t['user_id'] != \"e_2019310837\"]\n",
    "\n",
    "ds_peer = PDtable()\n",
    "for texp_id in exp_ids:\n",
    "    \n",
    "    exp_res = [t for t in peer_results.find({\"user_id\": texp_id})]\n",
    "    if len(exp_res) > 1:\n",
    "        print (\"Duplicated\", texp_id)\n",
    "        continue\n",
    "    exp_res = exp_res[0]\n",
    "    \n",
    "    # summary_time_list, estimate_time_list = parse_time_list(exp_res)\n",
    "    \n",
    "    print (texp_id, len(exp_res['peer_list']))\n",
    "    # for peer, task, result, st, et in zip(exp_res['peer_list'], exp_res['task_data'], exp_res['task_results'], summary_time_list, estimate_time_list):\n",
    "    for peer, task, result in zip(exp_res['peer_list'], exp_res['task_data'], exp_res['task_results']):\n",
    "        \n",
    "        if \"u_2019310837\" in peer:\n",
    "            continue\n",
    "        if len(result['peer_explanations_log']) == 0: # empty results\n",
    "            print (\"Empty results\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        #--------  Parse Questionnaires to items ---------# \n",
    "        log_list = result['peer_explanations_log']\n",
    "        if len(task['peer_candidates']) != len(result['peer_explanations_log']):\n",
    "            log_list = parse_peer_ans(result['peer_explanations_ans'])\n",
    "        \n",
    "        if len(task['peer_candidates']) != len(log_list):\n",
    "            print (\"Length not match, skip\", texp_id, peer, len(result['peer_explanations_log']))\n",
    "            continue\n",
    "        \n",
    "        print (\"--\", peer)\n",
    "        #--------  Main ---------# \n",
    "        for tm, texp in zip(task['peer_candidates'], log_list):\n",
    "            \n",
    "            #--------  For attributes ---------# \n",
    "            keydic = {u\"热度（评分数量）=1\": u\"pop\", u\"Ta的朋友也喜欢=1\": u\"user\", u'口味相似的其它人喜欢=1': \"user\", u\"和某部看过的电影相似=1\": u\"item\"}\n",
    "            shown_attrs = get_shown_attributes(tm['movieId'], ispeer=True)\n",
    "            attr_label = {}\n",
    "            for ta in shown_attrs:\n",
    "                if ta in keydic:\n",
    "                    attr_label[keydic[ta]] = \"normal\"\n",
    "                else:\n",
    "                    attr_label[ta] = \"normal\"\n",
    "                    \n",
    "            attrs = json.loads(texp['attr_factors']) if type(texp['attr_factors']) != list else texp['attr_factors']\n",
    "            for _t in attrs:\n",
    "                if type(_t) == str and _t.split(\"=\")[-1] in ['pos', 'neg', 'normal']:\n",
    "                    _k, _v, _l = _t.split(\"=\")\n",
    "                    \n",
    "                    key = \"{}={}\".format(_k, _v)\n",
    "                    if key in keydic:\n",
    "                        key = keydic[key]\n",
    "                    if key not in attr_label: # \n",
    "                        print (\"Error\", key)\n",
    "                    attr_label[key] = _l\n",
    "\n",
    "            peer_attributes = [\"{}={}\".format(k, v) for k, v in attr_label.items()] # all attribute labels\n",
    "            pos_attrs = [k for k, v in attr_label.items() if v == \"pos\"] # positive attributes\n",
    "            normal_attrs = [k for k, v in attr_label.items() if v == \"normal\"] \n",
    "            neg_attrs = [k for k, v in attr_label.items() if v == \"neg\"]\n",
    "            assert len(pos_attrs) + len(neg_attrs) + len(normal_attrs) == len(attr_label)\n",
    "            \n",
    "            \n",
    "            #--------  BUILD ---------# \n",
    "            ds_peer.add(peer, \"user_id\") # peer's peer is user\n",
    "            ds_peer.add(texp_id if texp_id != \"e_130152427992\" else \"e_13015242799\", \"peer_id\") # TODO: bug\n",
    "            \n",
    "            ds_peer.add(tm['movieId'], 'movie_id')\n",
    "            ds_peer.add(tm['title'], 'movie_title')\n",
    "            ds_peer.add(int(texp['peer_watch_intent']), \"peer_watch_intent\")\n",
    "            ds_peer.add(int(texp['peer_preference']), \"peer_preference\")\n",
    "            ds_peer.add(texp['peer_explanation_long'], 'peer_explanation_long')\n",
    "            \n",
    "            ds_peer.add(peer_attributes, \"peer_attributes\")\n",
    "            ds_peer.add(pos_attrs, \"peer_pos\")\n",
    "            ds_peer.add(normal_attrs, \"peer_normal\")\n",
    "            ds_peer.add(neg_attrs, \"peer_neg\")\n",
    "            \n",
    "            ds_peer.add(int(texp['peer_ifwatched']), 'peer_ifwatched')\n",
    "            ds_peer.add(int(texp['peer_own_preference']), 'peer_own_preference')\n",
    "            \n",
    "            # ds_peer.add(st, \"summary_time\")\n",
    "            # ds_peer.add(et, \"estimate_time\")\n",
    "            \n",
    "            ds_peer.add(result['user_summary_ans'][\"user_summary\"], \"user_summary\")\n",
    "        \n",
    "df_peer = ds_peer.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_up_items = df_user.merge(df_peer, on=[\"user_id\", \"movie_id\"], how=\"outer\")\n",
    "df_up_items.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = \"data/user-study/\"\n",
    "df_user.to_pickle(os.path.join(OUT_PATH, \"df_user.pkl\"))\n",
    "df_peer.to_pickle(os.path.join(OUT_PATH, \"df_peer.pkl\"))\n",
    "df_up_items.to_pickle(os.path.join(OUT_PATH, \"df_up_items.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statisitcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Finished Users: 17\n",
      "#Finished Peers: 19\n"
     ]
    }
   ],
   "source": [
    "finish_user_ids = set(df_up_items[pd.isnull(df_up_items[\"post_expected_preference\"]) == False]['user_id'])\n",
    "finish_peer_ids = set(df_up_items[pd.isnull(df_up_items[\"peer_preference\"]) == False]['peer_id'])\n",
    "\n",
    "print (\"#Finished Users:\", len(finish_user_ids))\n",
    "print (\"#Finished Peers:\", len(finish_peer_ids))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
